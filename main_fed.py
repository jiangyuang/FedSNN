#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Python version: 3.6

import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
import copy
import numpy as np
import pandas as pd
from pathlib import Path
from torchvision import datasets, transforms
import torch
import torch.nn as nn

from utils.sampling import mnist_iid, mnist_noniid, cifar_iid, cifar_non_iid, mnist_dvs_iid, mnist_dvs_non_iid, \
    nmnist_iid, nmnist_non_iid
from utils.options import args_parser
from models.Update import LocalUpdate
from models.Fed import FedLearn
from models.test import test_img
import models.vgg as ann_models
import models.resnet as resnet_models
import models.vgg_spiking_bntt as snn_models_bntt

import tables
import yaml
import glob

from PIL import Image

from pysnn.datasets import nmnist_train_test

if __name__ == '__main__':
    # parse args
    args = args_parser()
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')
    if args.device != 'cpu':
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    torch.set_default_tensor_type('torch.cuda.FloatTensor')

    dataset_keys = None
    h5fs = None
    # load dataset and split users
    if args.dataset == 'CIFAR10':
        trans_cifar = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
        dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)
        dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)
        if args.iid:
            dict_users = cifar_iid(dataset_train, args.num_users)
        else:
            dict_users = cifar_non_iid(dataset_train, args.num_classes, args.num_users)
    elif args.dataset == 'CIFAR100':
        trans_cifar = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
        dataset_train = datasets.CIFAR100('../data/cifar100', train=True, download=True, transform=trans_cifar)
        dataset_test = datasets.CIFAR100('../data/cifar100', train=False, download=True, transform=trans_cifar)
        if args.iid:
            dict_users = cifar_iid(dataset_train, args.num_users)
        else:
            dict_users = cifar_non_iid(dataset_train, args.num_classes, args.num_users)
    elif args.dataset == 'N-MNIST':
        dataset_train, dataset_test = nmnist_train_test("nmnist/data")
        if args.iid:
            dict_users = nmnist_iid(dataset_train, args.num_users)
        else:
            dict_users = nmnist_non_iid(dataset_train, args.num_classes, args.num_users)
    else:
        exit('Error: unrecognized dataset')
    # img_size = dataset_train[0][0].shape

    # build model
    model_args = {'args': args}
    if args.model[0:3].lower() == 'vgg':
        if args.snn:
            if args.dataset == 'N-MNIST':
                model_args = {'num_cls': args.num_classes, 'timesteps': 20, 'dvs': True, 'inp_maps': 2, 'img_size': 34}
            elif args.dataset == "DDD20":
                model_args = {'num_cls': 1, 'timesteps': 20, 'inp_maps': 1, 'img_size': 40}
            else:
                model_args = {'num_cls': args.num_classes, 'timesteps': 20}
            # net_glob = snn_models_bntt.SNN_VGG9_TBN(**model_args).cuda()
            net_glob = snn_models_bntt.SNN_VGG16_TBN(**model_args).cuda()
        else:
            model_args = {'vgg_name': args.model, 'labels': args.num_classes, 'dataset': args.dataset, 'kernel_size': 3,
                          'dropout': args.dropout}
            net_glob = ann_models.VGG(**model_args).cuda()
    elif args.model[0:6].lower() == 'resnet':
        if args.snn:
            pass
        else:
            model_args = {'num_cls': args.num_classes}
            net_glob = resnet_models.Network(**model_args).cuda()
    else:
        exit('Error: unrecognized model')
    print(net_glob)

    # copy weights
    if args.pretrained_model:
        net_glob.load_state_dict(torch.load(args.pretrained_model, map_location='cpu'))

    net_glob = nn.DataParallel(net_glob)
    # training
    loss_train_list = []
    cv_loss, cv_acc = [], []
    val_loss_pre, counter = 0, 0
    net_best = None
    best_loss = None
    val_acc_list, net_list = [], []

    # metrics to store
    ms_acc_train_list, ms_loss_train_list, ms_eva_train_list = [], [], []
    ms_acc_test_list, ms_loss_test_list, ms_eva_test_list = [], [], []
    ms_num_client_list, ms_tot_comm_cost_list, ms_avg_comm_cost_list, ms_max_comm_cost_list = [], [], [], []
    ms_tot_nz_grad_list, ms_avg_nz_grad_list, ms_max_nz_grad_list = [], [], []
    ms_sum_grads = []

    # testing
    net_glob.eval()
    # acc_train, loss_train = test_img(net_glob, dataset_train, args)
    # acc_test, loss_test = test_img(net_glob, dataset_test, args)
    # print("Initial Training accuracy: {:.2f}".format(acc_train))
    # print("Initial Testing accuracy: {:.2f}".format(acc_test))
    acc_train, loss_train, eva_train = 0, 0, 0
    acc_test, loss_test, eva_test = 0, 0, 0
    sum_grads = 0
    # Add metrics to store
    ms_acc_train_list.append(acc_train)
    ms_acc_test_list.append(acc_test)
    ms_loss_train_list.append(loss_train)
    ms_loss_test_list.append(loss_test)
    ms_eva_train_list.append(eva_train)
    ms_eva_test_list.append(eva_test)
    ms_sum_grads.append(sum_grads)

    # Define LR Schedule
    values = args.lr_interval.split()
    lr_interval = []
    for value in values:
        lr_interval.append(int(float(value) * args.epochs))

    # Define Fed Learn object
    fl = FedLearn(args)

    if args.initial_prune is not None:
        if args.prune_input_output:
            prune_rates = [0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05]
        else:
            prune_rates = [None, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, None]
        if args.initial_prune == "magnitude":
            net_glob.module.prune_by_pct(prune_rates)
        elif args.initial_prune == "random":
            net_glob.module.random_prune_by_pct(prune_rates)
        else:
            raise RuntimeError(f"{args.initial_prune} not supported")
        print(f"Pruning (at initialization) {prune_rates[0]} at input/output layer and {prune_rates[1]} "
              f"at other layers. Method = {args.initial_prune}")

    for iter in range(args.epochs):
        net_glob.train()
        w_locals, loss_locals = [], []
        m = max(int(args.frac * args.num_users), 1)
        idxs_users = np.random.choice(range(args.num_users), m, replace=False)
        print(idxs_users)
        for idx in idxs_users:
            if args.dataset == "DDD20":
                local = LocalUpdateDDD(args=args, dataset_keys=dataset_keys, h5fs=h5fs,
                                       client_id=idx)  # Takes in the client id and the dataloader later decides what data to assign this client
            else:
                local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[
                    idx])  # idxs needs the list of indices assigned to this particular client
            model_copy = type(net_glob.module)(**model_args)  # get a new instance
            model_copy = nn.DataParallel(model_copy)
            model_copy.load_state_dict(net_glob.state_dict())  # copy weights and stuff
            w, loss = local.train(net=model_copy.to(args.device))
            w_locals.append(copy.deepcopy(w))
            loss_locals.append(copy.deepcopy(loss))
        # update global weights
        w_glob = fl.FedAvg(w_locals, w_init=model_copy.state_dict())

        w_init = net_glob.state_dict()
        delta_w_locals = []
        sum_grads = 0
        for i in range(0, len(w_locals)):
            delta_w = {}
            for k in w_init.keys():
                delta_w[k] = w_locals[i][k] - w_init[k]
                sum_grads += torch.sum(torch.abs(delta_w[k]))
            delta_w_locals.append(delta_w)
        ms_sum_grads.append(sum_grads.item())

        # copy weight to net_glob
        net_glob.load_state_dict(w_glob)

        # print loss
        print(loss_locals)
        loss_avg = sum(loss_locals) / len(loss_locals)
        print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))
        loss_train_list.append(loss_avg)

        if iter % args.eval_every == 0:
            # testing
            net_glob.eval()
            if args.dataset == "DDD20":
                loss_train, eva_train = test_img_ddd(net_glob, args, h5fs, dataset_keys, 'train')
                print("Round {:d}, Training loss: {:.2f}".format(iter, loss_train))
                print("Round {:d}, Training EVA: {:.2f}".format(iter, eva_train))
                loss_test, eva_test = test_img_ddd(net_glob, args, h5fs, dataset_keys, 'test')
                print("Round {:d}, Testing loss: {:.2f}".format(iter, loss_test))
                print("Round {:d}, Testing EVA: {:.2f}".format(iter, eva_test))
            else:
                acc_train, loss_train = test_img(net_glob, dataset_train, args)
                print("Round {:d}, Training accuracy: {:.2f}".format(iter, acc_train))
                acc_test, loss_test = test_img(net_glob, dataset_test, args)
                print("Round {:d}, Testing accuracy: {:.2f}".format(iter, acc_test))

            # Add metrics to store
            ms_acc_train_list.append(acc_train)
            ms_acc_test_list.append(acc_test)
            ms_loss_train_list.append(loss_train)
            ms_loss_test_list.append(loss_test)
            ms_eva_train_list.append(eva_train)
            ms_eva_test_list.append(eva_test)

            print("Train accuracy", ms_acc_train_list)
            print("Test accuracy", ms_acc_test_list)
            print("Train loss", ms_loss_train_list)
            print("Test loss", ms_loss_test_list)

        if args.prune:
            if args.prune_input_output:
                prune_rates = [0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05]
            else:
                prune_rates = [None, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, None]
            net_glob.module.prune_by_pct([x / 10 for x in prune_rates])
            print(f"Pruning {prune_rates[0]} at input/output layer and {prune_rates[1]} at other layers.")

        if iter in lr_interval:
            args.lr = args.lr / args.lr_reduce

    Path('./{}'.format(args.result_dir)).mkdir(parents=True, exist_ok=True)
    # plot loss curve
    plt.figure()
    plt.plot(range(len(loss_train_list)), loss_train_list)
    plt.ylabel('train_loss')
    plt.savefig(
        './{}/fed_loss_{}_{}_{}_C{}_iid{}.png'.format(args.result_dir, args.dataset, args.model, args.epochs, args.frac,
                                                      args.iid))

    # testing
    net_glob.eval()
    if args.dataset == "DDD20":
        loss_train, eva_train = test_img_ddd(net_glob, args, h5fs, dataset_keys, 'train')
        print("Round {:d}, Training loss: {:.2f}".format(iter, loss_train))
        print("Round {:d}, Training EVA: {:.2f}".format(iter, eva_train))
        loss_test, eva_test = test_img_ddd(net_glob, args, h5fs, dataset_keys, 'test')
        print("Round {:d}, Testing loss: {:.2f}".format(iter, loss_test))
        print("Round {:d}, Testing EVA: {:.2f}".format(iter, eva_test))
    else:
        acc_train, loss_train = test_img(net_glob, dataset_train, args)
        print("Final Training accuracy: {:.2f}".format(acc_train))
        acc_test, loss_test = test_img(net_glob, dataset_test, args)
        print("Final Testing accuracy: {:.2f}".format(acc_test))

    # Add metrics to store
    ms_acc_train_list.append(acc_train)
    ms_acc_test_list.append(acc_test)
    ms_loss_train_list.append(loss_train)
    ms_loss_test_list.append(loss_test)
    ms_eva_train_list.append(eva_train)
    ms_eva_test_list.append(eva_test)
    ms_sum_grads.append(0)

    # plot loss curve
    plt.figure()
    plt.plot(range(len(ms_acc_train_list)), ms_acc_train_list)
    plt.plot(range(len(ms_acc_test_list)), ms_acc_test_list)
    plt.plot()
    plt.ylabel('Accuracy')
    plt.legend(['Training acc', 'Testing acc'])
    plt.savefig(
        './{}/fed_acc_{}_{}_{}_C{}_iid{}.png'.format(args.result_dir, args.dataset, args.model, args.epochs, args.frac,
                                                     args.iid))

    plt.figure()
    plt.plot(range(len(ms_eva_train_list)), ms_eva_train_list)
    plt.plot(range(len(ms_eva_test_list)), ms_eva_test_list)
    plt.plot()
    plt.ylabel('EVA')
    plt.legend(['Training EVA', 'Testing EVA'])
    plt.savefig(
        './{}/fed_eva_{}_{}_{}_C{}_iid{}.png'.format(args.result_dir, args.dataset, args.model, args.epochs, args.frac,
                                                     args.iid))

    # plot gradients curve
    plt.figure()
    plt.plot(range(len(ms_sum_grads[1:-1])), ms_sum_grads[1:-1])
    plt.ylabel('grads')
    plt.savefig('./{}/fed_grads_{}_{}_{}_C{}_iid{}.png'.format(args.result_dir, args.dataset, args.model, args.epochs,
                                                               args.frac, args.iid))

    # Write metric store into a CSV
    metrics_df = pd.DataFrame(
        {
            'Train acc': ms_acc_train_list,
            'Test acc': ms_acc_test_list,
            'Train loss': ms_loss_train_list,
            'Test loss': ms_loss_test_list,
            'Sum Grads': ms_sum_grads,
            'Train eva': ms_eva_train_list,
            'Test eva': ms_eva_test_list
        })
    metrics_df.to_csv(
        './{}/fed_stats_{}_{}_{}_C{}_iid{}.csv'.format(args.result_dir, args.dataset, args.model, args.epochs,
                                                       args.frac, args.iid), sep='\t')

    torch.save(net_glob.module.state_dict(), './{}/saved_model'.format(args.result_dir))
